# awesome-self-consuming-ai-papers
Papers about self-consuming generative models, which have a tendency to go MAD or collapse.

Sorted by upload date (oldest first). Updated as of 5/14/2024.

### "Solving" MADness:
1. Self-Correcting Self-Consuming Loops for Generative Model Training
2. Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data (Donoho's paper)

### Analyzing or explaining self-consumption/MADness:
1. On the Stability of Iterative Retraining of Generative Models on their own Data
2. Model Collapse Demystified: The Case of Regression
3. A Tale of Tails: Model Collapse as a Change of Scaling Laws (same authors as Model Collapse Demystified)
4. Towards Theoretical Understandings of Self-Consuming Generative Models
5. Heat Death of Generative Models in Closed-Loop Learning

### Additional observations of MADness in self-consumption:
1. [arXiv 23] Large Language Models Suffer From Their Own Output: An Analysis of the Self-Consuming Training Loop
2. The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text
3. Nepotistically Trained Generative-AI Models Collapse
4. AI and the Problem of Knowledge Collapse

### Ethical and societal implications of MADness:
1. Are large language models a threat to digital public goods? evidence from activity on stack overflow
2. Generative Artificial Intelligence Enhances Creativity but Reduces the Diversity of Novel Content
3. LLMs may dominate information access: Neural retrievers are biased towards LLM-generated texts

### Self-consumption for good (i.e., training generative models on AI-generated or AI-curated data):
1. Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk
2. Iterated Denoising Energy Matching for Sampling from Boltzmann Densities
3. Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion Models
4. How to Train Data-Efficient LLMs
